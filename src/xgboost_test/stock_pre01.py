#!---* coding: utf-8 --*--
#!/usr/bin/python
'''
Created on 2018å¹´1æœˆ30æ—¥
 æœ€è¿‘ï¼Œäººå·¥æ™ºèƒ½å¼•èµ·äº†å¤§å®¶å¹¿æ³›çš„å…³æ³¨ï¼Œå…¶åœ¨å›¾åƒè¯†åˆ«ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†æ–¹å‘éƒ½åšå‡ºäº†ä¸€äº›æˆæžœã€‚è¯¥é¢†åŸŸæ¯”è¾ƒå¸¸ç”¨çš„æ¨¡åž‹æœ‰çº¿æ€§å›žå½’ã€æ ‘æ¨¡åž‹ã€SVMï¼Œ é›†æˆå­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ æ¨¡åž‹(CNN, RNN)ï¼Œä»¥å¾€å¤§å®¶åœ¨é‡åŒ–æ–¹é¢ä¸»è¦é€‰å–çº¿æ€§å›žå½’æ¨¡åž‹ï¼Œå…¶åœ¨è§£é‡Šå› å­æ”¶ç›Šæ–¹é¢æ¯”è¾ƒç›´è§‚ï¼Œä½†è¿™ç§åšæ³•ä¼šä¸§å¤±ä¸€äº›éžçº¿æ€§çš„ç‰¹å¾å…³ç³»ã€‚
æœ¬æ–‡ä¸»è¦è€ƒå¯Ÿé›†æˆå­¦ä¹ åœ¨é‡åŒ–é€‰è‚¡æ–¹é¢çš„è¿ç”¨ï¼ŒåŒä¸Šè¿°ç ”æŠ¥ä¸€æ ·ï¼Œä¸»è¦é‡‡ç”¨é›†æˆå­¦ä¹ ä¸­çš„boostingæ–¹æ³•ï¼Œ é€‰å–äº†xgboostä½œä¸ºè®­ç»ƒæ¡†æž¶ï¼Œå¯¹é€‰å–çš„å› å­è¿›è¡Œåˆæˆï¼Œæœ€ç»ˆè€ƒå¯Ÿè¯¥åˆæˆå› å­çš„é€‰è‚¡æ•ˆæžœã€‚
# **æ•°æ®å‡†å¤‡**
--------
æœ¬æ–‡é€‰å–äº†ä¼˜çŸ¿çš„70ä¸ªå› å­ï¼Œæå–è‚¡ç¥¨æ¯ä¸ªæœˆæœ«çš„å› å­æš´éœ²ä½œä¸ºè®­ç»ƒè¾“å…¥ç‰¹å¾ã€‚è¯»è€…ä¹Ÿå¯ä»¥é€‰å–è‡ªå·±æ„Ÿå…´è¶£çš„å› å­ä½œä¸ºåŸºç¡€å› å­ã€‚
ç‰¹å¾æŒ‰ç…§ç ”æŠ¥ä¸­æ‰€æè¿°åšä¸­ä½æ•°åŽ»æžå€¼ï¼Œç¼ºå¤±å€¼å¤„ç†ï¼Œæ ‡å‡†åŒ–ç­‰ï¼Œè¯¥å¤„ç†åŽçš„æ•°æ®ä½œä¸ºæ¨¡åž‹è¾“å…¥ç‰¹å¾ã€‚åŒæ—¶åœ¨æ¯ä¸ªæœˆæœ«æˆªé¢æœŸï¼Œé€‰å–ä¸‹æœˆæ”¶ç›ŠæŽ’åå‰30%çš„è‚¡ç¥¨ä½œä¸ºæ­£ä¾‹ï¼ˆð‘¦=1ï¼‰ï¼ŒåŽ30%çš„è‚¡ç¥¨ä½œä¸ºè´Ÿä¾‹ï¼ˆð‘¦=âˆ’1ï¼‰ã€‚åˆ©ç”¨xgboostè¿›è¡Œåˆ†ç±»é¢„æµ‹ã€‚ç”±äºŽå¤„ç†æ•°æ®æºä»£ç è¿‡é•¿ï¼Œè¿™é‡Œä¸åšå±•ç¤ºï¼Œä¸”è¯¥éƒ¨åˆ†ä¹Ÿä¸å…·å¤‡å‚è€ƒä»·å€¼ï¼Œè¯»è€…å¯æ ¹æ®è‡ªå·±å¸¸ç”¨ç‰¹å¾å¤„ç†ä¹ æƒ¯è¿›è¡Œå¤„ç†ã€‚
@author: ljt
'''

import pandas as pd
import numpy as np
import xgboost as xgb
import matplotlib.pyplot as plt

filepath = u'../data/all_features.csv'
dxFeature = ["company_name", "judgedoc_is_no", "judgedoc_cnt", "litigant_defendant_cnt",
"near_3_year_judgedoc_cnt", "near_2_year_judgedoc_cnt",
"near_1_year_judgedoc_cnt", "litigant_defendant_contract_dispute_cnt",
  "litigant_defendant_bust_cnt",  "litigant_defendant_infringe_cnt",
  "litigant_defendant_intellectual_property_owner_cnt",
  "litigant_defendant_unjust_enrich_cnt",
  "litigant_result_sum_money",  "net_judgedoc_defendant_cnt", "shixin_is_no",
  "shixin_cnt", "near_3_year_shixin_cnt", "near_2_year_shixin_cnt",
  "near_1_year_shixin_cnt", "court_announce_is_no", "court_announce_cnt",
  "court_announce_litigant_cnt",  "court_notice_is_no", "court_notice_cnt",
  "court_notice_litigant_cnt",  "industry", "province", "regcap", "zczjbz",
  "established_years",  "fr_change_cnt",  "address_change_cnt", "regcap_change_cnt",
  "share_change_cnt", "network_fr_share_change_cnt",  "network_share_shixin_cnt",
  "zhixing_cnt",  "sszc_cnt", "punish_cnt", "judge_doc_cnt",  "cancel_cnt",
  "bidding_cnt",  "bidding_three_year_rate",  "is_black_list",  "is_escape",
  "is_diff_raise_money",  "is_stop_busi", "is_lost_with_money", "is_just_lost",
  "invent_publish_cnt", "invent_patent_cnt",  "utility_publish_cnt",
  "invent_publish_three_year_rate", "invent_patent_three_year_rate",
  "utility_publish_three_year_rate",  "warn_cnt", "fine_cnt", "revoking_cnt",
  "warn_cnt_three_year_rate", "fine_cnt_three_year_rate", "revoking_cnt_three_year_rate",
  "estate_auction_cnt", "real_estate_auction_cnt",  "trade_mark_cnt",
  "trademark_three_year_rate"]

def dataread():
    # df = pd.read_csv(filepath, names=dxFeature, encoding='utf-8', header=None)
    df = pd.read_csv(filepath, header=None, names=dxFeature)
    print (df.head())
    return df


class BoostModel:
    def __init__(self, max_depth=3, subsample=0.95, num_round=2000, early_stopping_rounds=50):
        self.params = {'max_depth': max_depth, 'eta': 0.1, 'silent': 1, 'alpha': 0.5, 'lambda': 0.5,
                       'eval_metric': 'auc', 'subsample': subsample, 'objective': 'binary:logistic'}
        self.num_round = num_round
        self.early_stopping_rounds = early_stopping_rounds

    def fit(self, train_data, train_label, val_data, val_label):
        dtrain = xgb.DMatrix(train_data, label=train_label)
        deval = xgb.DMatrix(val_data, label=val_label)

        boost_model = xgb.train(self.params, dtrain, num_boost_round=self.num_round,
                                evals=[(dtrain, 'train'), (deval, 'eval')],
                                early_stopping_rounds=self.early_stopping_rounds, verbose_eval=False)
        print('get best eval auc : %s, in step %s' % (boost_model.best_score, boost_model.best_iteration))
        self.boost_model = boost_model

        return boost_model

    def predict(self, test_data):
        dtest = xgb.DMatrix(test_data)
        predict_score = self.boost_model.predict(dtest, ntree_limit=self.boost_model.best_ntree_limit)

        return predict_score


def get_train_val_test_data(year, split_pct=0.9):
    df = dataread()
    back_year = max(2007, year - 6)
    train_val_df = df[(df['year'] >= back_year) & (df['year'] < year)]
    train_val_df = train_val_df.sample(frac=1).reset_index(drop=True)

    # æ‹†åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†
    train_df = train_val_df.iloc[0:int(len(train_val_df) * split_pct)]
    val_df = train_val_df.iloc[int(len(train_val_df) * split_pct):]

    test_df = df[df['year'] == year]

    return train_df, val_df, test_df


def format_feature_label(origin_df, is_filter=True):
    if is_filter:
        origin_df = origin_df[origin_df['label'] != 0]
        # å› å­xgboostçš„labelè¾“å…¥èŒƒå›´åªèƒ½æ˜¯[0, 1]ï¼Œéœ€è¦å¯¹åŽŸå§‹labelè¿›è¡Œæ›¿æ¢
        origin_df['label'] = origin_df['label'].replace(-1, 0)

    feature = np.array(origin_df[factors])
    label = np.array(origin_df['label'])

    return feature, label


def write_factor_to_csv(df, predict_score, year):
    # è®°å½•æ¨¡åž‹é¢„æµ‹åˆ†æ•°ä¸ºå› å­å€¼ï¼Œè¾“å‡º
    df['factor'] = predict_score
    df = df.loc[:, ['ticker', 'tradeDate', 'label', 'factor']]
    is_header = True
    if year != 2011:
        is_header = False

    df.to_csv('./raw_data/factor.csv', mode='a+', encoding='utf-8', header=is_header)


def pipeline():
    boost_model_list = []
    for year in range(2011, 2018):
        print('training model for %s' % year)
        train_df, val_df, test_df = get_train_val_test_data(year)
        boost_model = BoostModel()
        train_feature, train_label = format_feature_label(train_df)
        val_feature, val_label = format_feature_label(val_df)

        boost_model.fit(train_feature, train_label, val_feature, val_label)

        test_feature, test_label = format_feature_label(test_df, False)
        predict_score = boost_model.predict(test_feature)

        write_factor_to_csv(test_df, predict_score, year)
        boost_model_list.append(boost_model)

    return boost_model_list

from datetime import datetime
from sklearn.metrics import roc_auc_score
# è®¡ç®—äºŒåˆ†ç±»æ¨¡åž‹æ ·æœ¬å¤–çš„ACCä¸ŽAUC
def get_test_auc_acc():

    df = pd.read_csv('./raw_data/factor.csv')
    # åªæŸ¥çœ‹åŽŸæœ‰labelä¸º+1, -1çš„æ•°æ®
    df = df[df['label'] != 0]
    df.loc[:, 'predict'] = df.loc[:, 'factor'].apply(lambda x: 1 if x > 0.5 else -1)

    acc_list = []
    auc_list = []
    for date, group in df.groupby('tradeDate'):
        df_correct = group[group['predict'] == group['label']]
        correct = len(df_correct) * 1.0 / len(group)
        auc = roc_auc_score(np.array(group['label']), np.array(group['factor']))
        acc_list.append([date, correct])
        auc_list.append([date, auc])

    acc_list = sorted(acc_list, key=lambda x: x[0], reverse=False)
    mean_acc = sum([item[1] for item in acc_list]) / len(acc_list)

    auc_list = sorted(auc_list, key=lambda x: x[0], reverse=False)
    mean_auc = sum([item[1] for item in auc_list]) / len(auc_list)

    return acc_list, auc_list, round(mean_acc, 2), round(mean_auc, 2)


def plot_accuracy_curve():
    acc_list, auc_list, mean_acc, mean_auc = get_test_auc_acc()

    plt.plot([datetime.strptime(str(item[0]), '%Y%m%d') for item in acc_list], [item[1] for item in acc_list], '-bo')
    plt.plot([datetime.strptime(str(item[0]), '%Y%m%d') for item in auc_list], [item[1] for item in auc_list], '-ro')

    plt.legend([u"acc curve: mean_acc:%s" % mean_acc, u"auc curve: mean auc:%s" % mean_auc], loc='upper left',
               handlelength=2, handletextpad=0.5, borderpad=0.1)
    plt.ylim((0.3, 0.8))
    plt.show()


def get_feature_importance():
    df = pd.DataFrame(index=factors, columns=range(2011, 2018))
    for i, column in enumerate(range(2011, 2018)):
        feature_importance = boost_model_list[i].boost_model.get_score(importance_type='weight')
        df[column] = pd.Series(index=[factors[int(key.replace('f', ''))] for key, value in feature_importance.items()],
                               data=[value for key, value in feature_importance.items()])
        df[column] = df[column].fillna(0.0)
        df[column] = 1 + np.argsort(np.argsort(df[column]))

    df['all'] = df.mean(axis=1)

    return df.sort_values('all', ascending=False)




if __name__ == '__main__':
    dataread()
    boost_model_list = pipeline()
    plot_accuracy_curve()
    feature_importance_df = get_feature_importance()
    feature_importance_df.iloc[np.r_[0:10, -10:0]]